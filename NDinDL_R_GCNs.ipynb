{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "asMhF2nA-FeE"
   },
   "source": [
    "# New developments in deep learning - R-GCNs\n",
    "Isotropic Graph Neural Networks \n",
    "- Representations are learned via differentiable message passing scheme \n",
    "-  All neighbors are treated as equally important \n",
    "-  Starting points: \n",
    "  -  Kipf & Welling: “Semi-Supervised Classification with Graph Convolutional Networks” (https://arxiv.org/abs/1609.02907) \n",
    "  -  Schlichtkrull et al.: “Modeling Relational Data with Graph Convolutional Networks” (https://arxiv.org/abs/1703.06103) \n",
    "- Task: \n",
    "  - Implement Relational Graph convolutional Neural Network for Node Classification\n",
    "\n",
    "Blog posts:\n",
    "- https://towardsdatascience.com/how-to-do-deep-learning-on-graphs-with-graph-convolutional-networks-7d2250723780\n",
    "- http://tkipf.github.io/graph-convolutional-networks/\n",
    "\n",
    "Jupyter notebook tutorial:\n",
    "- https://github.com/TobiasSkovgaardJepsen/posts/blob/master/HowToDoDeepLearningOnGraphsWithGraphConvolutionalNetworks/Part2_SemiSupervisedLearningWithSpectralGraphConvolutions/notebook.ipynb\n",
    "\n",
    "Keras implementation:\n",
    "- https://github.com/tkipf/relational-gcn\n",
    "PyTorch implementations\n",
    "- https://github.com/tkipf/pygcn \n",
    "- https://github.com/masakicktashiro/rgcn_pytorch_implementation\n",
    "- https://github.com/mjDelta/relation-gcn-pytorch\n",
    "\n",
    "Dataset:\n",
    "- https://ogb.stanford.edu\n",
    "- https://ogb.stanford.edu/docs/nodeprop/#ogbn-proteins\n",
    "- https://ogb.stanford.edu/docs/leader_nodeprop/#ogbn-proteins "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mqY7yxkK_GR3"
   },
   "source": [
    "## Relational GCNs - Theory\n",
    "Extension of GCNs: Use a set of relation-specific weight matrices $W_r^{(l)}$, where $r \\in R$ denotes the relation type\n",
    "\n",
    "Propagation model:\n",
    "> $h_i^{l+1} = \\sigma\\left(\\sum_{r\\in R}\\sum_{j\\in N^r_i}\\frac{1}{c_{i,r}}W_r^{(l)}h_j^{(l)}+\\underbrace{W_0^{(l)}h_i^{(l)}}_{\\text{self-connection}}\\right)$\n",
    "\n",
    "where \n",
    "- $N^r_i$ denotes the set of neighbor indices of node $i$ under relation $r \\in R$, \n",
    "- $c_{i,r}$ is a problem-specific normalization constant that can either be learned or chosen in advance (such as $c_{i,r} = |N_i^r|$).\n",
    "\n",
    "Neural network layer update: evaluate message passing update in parallel for every node $i \\in V$.\n",
    "\n",
    "Parameter sharing for highly- multi-relational data: basis decomposition of relation-specific weight matrices\n",
    "> $W_r^{(l)} = \\sum^B_{b=1}a^{(l)}_{r,b}V_b^{(l)}$\n",
    "\n",
    "Linear combination of basis transformations $V_b^{(l)} \\in \\mathbb{R}^{d^{(l+1)}\\times d^{(l)}}$ with learnable coefficients $a^{(l)}_{r,b}$ such that only the coefficients depend on $r$. $B$, the number of basis functions, is a hyperparameter.\n",
    "\n",
    "For entity classification as described in the paper minimize:\n",
    "> $L = -\\sum_{i\\in Y}\\sum^K_{k=1}t_{i,k}\\ln h_{i,k}^{(l)}$\n",
    "\n",
    "whre:\n",
    "- $Y$ is the set of node indices with labels\n",
    "- $K$ is the number of classes (?)\n",
    "- $t_{i,k}$ is the ground-truth label\n",
    "- $h_{i,k}^{(l)}$ is the $k$-th entry of network ouput for $i$-th labeled node\n",
    "\n",
    "Training and evaluation\n",
    "- 2 layer model with 16 hidden units (dimension of hidden node representation)\n",
    "- 50 epochs with learning rate 0.01 using Adam optimizer\n",
    "- normalization constant $c_{i,r} = |N_i^r|$, i.e. average all incoming messages from a particular relation type\n",
    "- $l2$ penalty on first layer weights $C_{l2} \\in \\{0, 5\\cdot 10^{-4}\\}$\n",
    "- number of basis functions $B \\in \\{0, 10, 20, 30, 40\\}$\n",
    "\n",
    "Results reported\n",
    "- Accuracy and standard error over 10 runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets: AIFB, MUTAG\n",
    "**AIFB**: \n",
    "Describes the AIFB research institute, predict affiliation to research group\n",
    "\n",
    "4 classes, 45 relations, 8k entities, 28k edges, 176 labelled instances\n",
    "\n",
    "**MUTAG**:\n",
    "Information about complex molecules that are potentially carcinogenic\n",
    "\n",
    "2 classes, 23 relations, 23k entities, 74k edges, 340 labelled instances\n",
    "\n",
    "### References\n",
    "Ristoski, P., De Vries, G. K. D., & Paulheim, H. (2016, October). A collection of benchmark datasets for systematic evaluations of machine learning on the semantic web. In International Semantic Web Conference (pp. 186-194). Springer, Cham"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eQOMGMlHF060"
   },
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"AIFB\"  # choices=['AIFB', 'MUTAG', 'BGS', 'AM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/rusty1s/pytorch_geometric/blob/master/examples/rgcn.py\n",
    "import os.path as osp\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "from torch_geometric.datasets import Entities\n",
    "from torch_geometric.nn import RGCNConv\n",
    "\n",
    "path = osp.join('.', 'data', 'Entities')\n",
    "dataset = Entities(path, dataset_name)\n",
    "data = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.num_relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/rusty1s/pytorch_geometric/blob/master/torch_geometric/utils/num_nodes.py\n",
    "def maybe_num_nodes(edge_index, num_nodes=None):\n",
    "    if num_nodes is not None:\n",
    "        return num_nodes\n",
    "    elif isinstance(edge_index, Tensor):\n",
    "        return int(edge_index.max()) + 1\n",
    "    else:\n",
    "        return max(edge_index.size(0), edge_index.size(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.num_nodes = maybe_num_nodes(data.edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.num_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FRIGn4OrF22_"
   },
   "source": [
    "## R-GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/rusty1s/pytorch_geometric/blob/master/examples/rgcn.py\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = RGCNConv(data.num_nodes, 16, dataset.num_relations,\n",
    "                              num_bases=30)\n",
    "        self.conv2 = RGCNConv(16, dataset.num_classes, dataset.num_relations,\n",
    "                              num_bases=30)\n",
    "\n",
    "    def forward(self, edge_index, edge_type):\n",
    "        x = F.relu(self.conv1(None, edge_index, edge_type))\n",
    "        x = self.conv2(x, edge_index, edge_type)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model, data = Net().to(device), data.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=0.0005)\n",
    "\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.edge_index, data.edge_type)\n",
    "    loss = F.nll_loss(out[data.train_idx], data.train_y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test():\n",
    "    model.eval()\n",
    "    pred = model(data.edge_index, data.edge_type).argmax(dim=-1)\n",
    "    train_acc = pred[data.train_idx].eq(data.train_y).to(torch.float).mean()\n",
    "    test_acc = pred[data.test_idx].eq(data.test_y).to(torch.float).mean()\n",
    "    return train_acc.item(), test_acc.item()\n",
    "\n",
    "\n",
    "for epoch in range(1, 51):\n",
    "    loss = train()\n",
    "    train_acc, test_acc = test()\n",
    "    print(f'Epoch: {epoch:02d}, Loss: {loss:.4f}, Train: {train_acc:.4f} '\n",
    "          f'Test: {test_acc:.4f}')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "NDinDL_R-GCNs.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (NDinDL)",
   "language": "python",
   "name": "ndindl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
