{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "asMhF2nA-FeE"
   },
   "source": [
    "# New developments in deep learning - R-GCNs\n",
    "Isotropic Graph Neural Networks \n",
    "- Representations are learned via differentiable message passing scheme \n",
    "-  All neighbors are treated as equally important \n",
    "-  Starting points: \n",
    "  -  Kipf & Welling: “Semi-Supervised Classification with Graph Convolutional Networks” (https://arxiv.org/abs/1609.02907) \n",
    "  -  Schlichtkrull et al.: “Modeling Relational Data with Graph Convolutional Networks” (https://arxiv.org/abs/1703.06103) \n",
    "- Task: \n",
    "  - Implement Relational Graph convolutional Neural Network for Node Classification\n",
    "\n",
    "Blog posts:\n",
    "- https://towardsdatascience.com/how-to-do-deep-learning-on-graphs-with-graph-convolutional-networks-7d2250723780\n",
    "- http://tkipf.github.io/graph-convolutional-networks/\n",
    "\n",
    "Jupyter notebook tutorial:\n",
    "- https://github.com/TobiasSkovgaardJepsen/posts/blob/master/HowToDoDeepLearningOnGraphsWithGraphConvolutionalNetworks/Part2_SemiSupervisedLearningWithSpectralGraphConvolutions/notebook.ipynb\n",
    "\n",
    "Keras implementation:\n",
    "- https://github.com/tkipf/relational-gcn\n",
    "PyTorch implementations\n",
    "- https://github.com/tkipf/pygcn \n",
    "- https://github.com/masakicktashiro/rgcn_pytorch_implementation\n",
    "- https://github.com/mjDelta/relation-gcn-pytorch\n",
    "\n",
    "Dataset:\n",
    "- https://ogb.stanford.edu\n",
    "- https://ogb.stanford.edu/docs/nodeprop/#ogbn-proteins\n",
    "- https://ogb.stanford.edu/docs/leader_nodeprop/#ogbn-proteins "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mqY7yxkK_GR3"
   },
   "source": [
    "## Relational GCNs\n",
    "Extension of GCNs: Use a set of relation-specific weight matrices $W_r^{(l)}$, where $r \\in R$ denotes the relation type\n",
    "\n",
    "Propagation model:\n",
    "> $h_i^{l+1} = \\sigma\\left(\\sum_{r\\in R}\\sum_{j\\in N^r_i}\\frac{1}{c_{i,r}}W_r^{(l)}h_j^{(l)}+\\underbrace{W_0^{(l)}h_i^{(l)}}_{\\text{self-connection}}\\right)$\n",
    "\n",
    "where \n",
    "- $N^r_i$ denotes the set of neighbor indices of node $i$ under relation $r \\in R$, \n",
    "- $c_{i,r}$ is a problem-specific normalization constant that can either be learned or chosen in advance (such as $c_{i,r} = |N_i^r|$).\n",
    "\n",
    "Neural network layer update: evaluate message passing update in parallel for every node $i \\in V$.\n",
    "\n",
    "Parameter sharing for highly- multi-relational data: basis decomposition of relation-specific weight matrices\n",
    "> $W_r^{(l)} = \\sum^B_{b=1}a^{(l)}_{r,b}V_b^{(l)}$\n",
    "\n",
    "Linear combination of basis transformations $V_b^{(l)} \\in \\mathbb{R}^{d^{(l+1)}\\times d^{(l)}}$ with learnable coefficients $a^{(l)}_{r,b}$ such that only the coefficients depend on $r$. $B$, the number of basis functions, is a hyperparameter.\n",
    "\n",
    "For entity classification as described in the paper minimize:\n",
    "> $L = -\\sum_{i\\in Y}\\sum^K_{k=1}t_{i,k}\\ln h_{i,k}^{(l)}$\n",
    "\n",
    "whre:\n",
    "- $Y$ is the set of node indices with labels\n",
    "- $K$ is the number of classes (?)\n",
    "- $t_{i,k}$ is the ground-truth label\n",
    "- $h_{i,k}^{(l)}$ is the $k$-th entry of network ouput for $i$-th labeled node\n",
    "\n",
    "# Training and evaluation\n",
    "- 2 layer model with 16 hidden units (dimension of hidden node representation)\n",
    "- 50 epochs with learning rate 0.01 using Adam optimizer\n",
    "- normalization constant $c_{i,r} = |N_i^r|$, i.e. average all incoming messages from a particular relation type\n",
    "- $l2$ penalty on first layer weights $C_{l2} \\in \\{0, 5\\cdot 10^{-4}\\}$\n",
    "- number of basis functions $B \\in \\{0, 10, 20, 30, 40\\}$\n",
    "\n",
    "Results reported\n",
    "- Accuracy and standard error over 10 runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FRIGn4OrF22_"
   },
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hj50NDlxFZdW"
   },
   "source": [
    "### Installing requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eQOMGMlHF060"
   },
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K-jEyPUpgN3S"
   },
   "outputs": [],
   "source": [
    "d_name = 'ogbn-proteins'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gZDjaFD5F9tn",
    "outputId": "9a434b99-f013-476a-a592-e66cca8fb1ad"
   },
   "outputs": [],
   "source": [
    "from ogb.nodeproppred import NodePropPredDataset\r\n",
    "\r\n",
    "dataset = NodePropPredDataset(name = d_name)\r\n",
    "\r\n",
    "split_idx = dataset.get_idx_split()\r\n",
    "train_idx, valid_idx, test_idx = split_idx[\"train\"], split_idx[\"valid\"], split_idx[\"test\"]\r\n",
    "graph, label = dataset[0] # graph: library-agnostic graph object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pXEJJ3CKhdZZ"
   },
   "source": [
    "The library-agnostic graph object is a dictionary containing the following keys: `edge_index`, `edge_feat`, `node_feat`, and `num_nodes`, which are detailed below.\r\n",
    "\r\n",
    "- `edge_index`: numpy arrays of shape (2, `num_edges`), where each column represents an edge. The first row and the second row represent the indices of source and target nodes. Undirected edges are represented by bi-directional edges.\r\n",
    "- `edge_feat`: numpy arrays of shape (`num_edges`, `edgefeat_dim`), where `edgefeat_dim` is the dimensionality of edge features and i-th row represents the feature of i-th edge. This can be None if no input edge features are available.\r\n",
    "- `node_feat`: numpy arrays of shape (`num_nodes`, `nodefeat_dim`), where `nodefeat_dim` is the dimensionality of node features and i-th row represents the feature of i-th node. This can be None if no input node features are available.\r\n",
    "- `num_nodes`: number of nodes in the graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uh4BV3o5GHDg"
   },
   "source": [
    "###  Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected input format of Evaluator for ogbn-proteins\n",
    "`{'y_true': y_true, 'y_pred': y_pred}`\n",
    "- `y_true`: numpy ndarray or torch tensor of shape (`num_node`, `num_task`)\n",
    "- `y_pred`: numpy ndarray or torch tensor of shape (`num_node`, `num_task`)\n",
    "where y_pred stores score values (for computing ROC-AUC),\n",
    "num_task is 112, and each row corresponds to one node.\n",
    "\n",
    "Expected output format of Evaluator for ogbn-proteins\n",
    "`{'rocauc': rocauc}`\n",
    "- `rocauc` (float): ROC-AUC score averaged across 112 task(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "trzDUGzWGHNK"
   },
   "outputs": [],
   "source": [
    "from ogb.nodeproppred import Evaluator\r\n",
    "\r\n",
    "evaluator = Evaluator(name = d_namat) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nVZVduLqgTLb"
   },
   "outputs": [],
   "source": [
    "# In most cases, input_dict is\r\n",
    "# input_dict = {\"y_true\": y_true, \"y_pred\": y_pred}\r\n",
    "result_dict = evaluator.eval(input_dict)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "NDinDL_R-GCNs.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (NDinDL)",
   "language": "python",
   "name": "ndindl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
